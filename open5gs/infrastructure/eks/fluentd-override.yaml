---
#override.yaml:
fluentd:
  configMapConfigs:
    - fluentd-prometheus-conf
  # The line below must be kept intact to disable the systemd conf because it is enabled in the underlying chart
  # Learn more here: https://github.com/coralogix/telemetry-shippers/blob/master/logs/fluentd/k8s-helm/http/README.md
  # - fluentd-systemd-conf 
  env:
    - name: APP_NAME
      value: namespace_name
    - name: SUB_SYSTEM
      value: container_name
    - name: APP_NAME_SYSTEMD
      value: systemd
    - name: SUB_SYSTEM_SYSTEMD
      value: kubelet.service
    - name: ENDPOINT
      value: api.coralogix.us
    - name: "FLUENTD_CONF"
      value: "../../etc/fluent/fluent.conf"
    - name: LOG_LEVEL
      value: error
    - name: K8S_NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
fileConfigs:
    coralogix.conf: |-
      <system>
        log_level "#{ENV['LOG_LEVEL']}"
      </system>
    
      <source>
        @type tail
        @id in_tail_container_logs
        path /var/log/containers/*.log
        path_key filename
        pos_file /var/log/fluentd-containers.log.pos
        tag raw.containers.*
        read_from_head false
        <parse>
        @type multi_format
          <pattern>
            format json
            time_key time
            time_format %Y-%m-%dT%H:%M:%S.%NZ
            keep_time_key true
          </pattern>
          <pattern>
            format /^(?<time>.+) (?<stream>stdout|stderr) [^ ]* (?<log>.*)$/
            time_format %Y-%m-%dT%H:%M:%S.%N%:z
            keep_time_key true
          </pattern>
        </parse>
      </source>
      
      # This Segment is using the detect-exceptions-plugin
      # It will scan the "log" field for well known sctructures of Exception messages
      # I any are found it will assemble them and will aatempt to resolve the multiline.
      # this segment will also remove the "raw" prefix fro mthe tag
      <match raw.containers.**>
        @id raw.containers
        @type detect_exceptions
        remove_tag_prefix raw
        message log
        stream stream
        multiline_flush_interval 5
        max_bytes 500000
        max_lines 1000
      </match>

      # This Segment takes the raw logs and enriches them with the kubernetes metadata
      # Other Parts in this config are relaying on it.
      <filter containers.**>
        @type kubernetes_metadata
        @id filter_kube_metadata
        skip_labels false
        skip_container_metadata false
        skip_namespace_metadata true
        skip_master_url true
      </filter>

      # Tag rewrite segment
      # This Section added a tag prefix based on the container name
      # This can be used to better utilize the concat plugin usage.
      <match containers.**>
         @type rewrite_tag_filter
         <rule>
           key $.kubernetes.container_name
           pattern ^(.+)$
           tag $1.${tag}
         </rule>
      </match>

      # This segment is here to block out the FluentD DS logs from being sent.
      # Any container name added to this list will be dropped and not sent to Coralogix.
      # This segment is dependent on the Tag re write segment to come first
      <match {fluentd}.containers.** kubernetes.var.log.containers.**sandbox**>
        @type null
      </match>

      <filter *.containers.**>
        @type record_transformer
        enable_ruby true
        auto_typecast true
        renew_record true
        <record>
          privateKey "#{ENV['PRIVATE_KEY']}"
          applicationName ${record.dig("kubernetes", "#{ENV['APP_NAME']}")}
          subsystemName ${record.dig("kubernetes", "#{ENV['SUB_SYSTEM']}")}
          computerName ${record.dig("kubernetes", "host")}
          timestamp ${time.strftime('%s%L')}
          text ${record.to_json}
        </record>
      </filter>

      # This segment will relabel Any message that reaches here.
      # This label will later be used to send all the logs to coralogix
      <match **>
        @type relabel
        @label @DISPATCH
      </match>
    
      <label @DISPATCH>
        <filter internal-kubernetes.systemd>
          @type record_transformer
          enable_ruby true
          auto_typecast true
          renew_record true
          <record>
            privateKey "#{ENV['PRIVATE_KEY']}"
            applicationName "#{ENV['APP_NAME_SYSTEMD']}"
            subsystemName "#{ENV['SUB_SYSTEM_SYSTEMD']}"
            timestamp ${time.strftime('%s%L')}
            text ${record.to_json}
          </record>
        </filter>
       # This segment will generate a metric of messages being sent to coralogix
       # It will enable a closer monitor of the sending process
        <filter **>
          @type prometheus
          <metric>
            name fluentd_input_status_num_records_total
            type counter
            desc The total number of incoming records
          </metric>
        </filter>
       
        <match **>
          @type http
          endpoint "https://#{ENV['ENDPOINT']}/logs/rest/singles"
          headers_from_placeholders {"private_key":"${$.privateKey}"}
          error_response_as_unrecoverable false
          <buffer $.privateKey>
            @type memory
            compress gzip
            flush_thread_count 4
            chunk_limit_size 6MB
            flush_interval 1s
            overflow_action throw_exception
            retry_max_times 10
            retry_type periodic
            retry_wait 8
          </buffer>
          <secondary>
            #If any messages fail to send they will be send to STDOUT for debug.
            @type stdout
          </secondary>
        </match>
      </label>